{
 "metadata": {
  "name": "04B_measuring_prediction_performance"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Measuring prediction performance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Checking Performance on the Iris Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Previously, we looked at a simplistic example of how to test the performance\n",
      "of a classifier.  Using the iris data set, it looked something like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the data\n",
      "from sklearn.datasets import load_iris\n",
      "iris = load_iris()\n",
      "X = iris.data\n",
      "y = iris.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate and train the classifier\n",
      "from sklearn.svm import LinearSVC\n",
      "clf = LinearSVC(loss = 'l2')\n",
      "clf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check input vs. output labels\n",
      "y_pred = clf.predict(X)\n",
      "print (y_pred == y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question:** what might be the problem with this approach?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A Better Approach: Using a validation set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Learning the parameters of a prediction function and testing it on the\n",
      "same data is a methodological mistake: a model that would just repeat\n",
      "the labels of the samples that it has just seen would have a perfect\n",
      "score but would fail to predict anything useful on yet-unseen data.\n",
      "\n",
      "To avoid over-fitting, we have to define two different sets:\n",
      "\n",
      "- a training set X_train, y_train which is used for learning the parameters of a predictive model\n",
      "- a testing set X_test, y_test which is used for evaluating the fitted predictive model\n",
      "\n",
      "In scikit-learn such a random split can be quickly computed with the\n",
      "`train_test_split` helper function.  It can be used this way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.25, random_state=0)\n",
      "\n",
      "print X.shape, X_train.shape, X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we train on the training data, and test on the testing data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = LinearSVC(loss='l2').fit(X_train, y_train)\n",
      "y_pred = clf.predict(X_test)\n",
      "print (y_pred == y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}